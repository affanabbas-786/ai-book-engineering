"use strict";(globalThis.webpackChunkmatrix_book=globalThis.webpackChunkmatrix_book||[]).push([[642],{8453:(t,e,n)=>{n.d(e,{R:()=>s,x:()=>i});var r=n(6540);const a={},o=r.createContext(a);function s(t){const e=r.useContext(o);return r.useMemo(function(){return"function"==typeof t?t(e):{...e,...t}},[e,t])}function i(t){let e;return e=t.disableParentContext?"function"==typeof t.components?t.components(a):t.components||a:s(t.components),r.createElement(o.Provider,{value:e},t.children)}},8783:(t,e,n)=>{n.r(e),n.d(e,{assets:()=>c,contentTitle:()=>i,default:()=>l,frontMatter:()=>s,metadata:()=>r,toc:()=>h});const r=JSON.parse('{"id":"chapter-6-chatbot-integration","title":"chapter-6-chatbot-integration","description":"---","source":"@site/docs/chapter-6-chatbot-integration.md","sourceDirName":".","slug":"/chapter-6-chatbot-integration","permalink":"/docs/chapter-6-chatbot-integration","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 5 \u2013 Qdrant Cloud + Embeddings + FastAPI","permalink":"/docs/chapter-5-qdrant-setup"},"next":{"title":"chapter-7-subagents-skills","permalink":"/docs/chapter-7-subagents-skills"}}');var a=n(4848),o=n(8453);const s={},i=void 0,c={},h=[{value:"6\ufe0f\u20e3 <code>chapter-6-chatbot-integration.md</code>",id:"6\ufe0f\u20e3-chapter-6-chatbot-integrationmd",level:2}];function d(t){const e={code:"code",h2:"h2",hr:"hr",pre:"pre",...(0,o.R)(),...t.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(e.hr,{}),"\n",(0,a.jsxs)(e.h2,{id:"6\ufe0f\u20e3-chapter-6-chatbot-integrationmd",children:["6\ufe0f\u20e3 ",(0,a.jsx)(e.code,{children:"chapter-6-chatbot-integration.md"})]}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-markdown",children:'---\r\nid: chapter-6-chatbot-integration\r\ntitle: Chapter 6 \u2013 Integrating ChatKit Chatbot into the Book\r\n---\r\n\r\nNow we connect the **FastAPI RAG backend** to a **chat interface** that appears inside the Docusaurus site.\r\n\r\nWe use **OpenAI ChatKit / Agents SDK** to build a flexible chatbot client.\r\n\r\n## ChatKit Overview\r\n\r\nChatKit helps you:\r\n\r\n- Define conversation state and tools  \r\n- Call your own backend (FastAPI) as a tool  \r\n- Stream responses to the frontend  \r\n- Build customized chat experiences\r\n\r\n## High-Level Flow\r\n\r\n1. User opens the **Chat** page inside the Docusaurus book  \r\n2. User types a question (or selects some text and then asks a question)  \r\n3. Frontend sends the question to FastAPI `/query` endpoint  \r\n4. FastAPI:\r\n   - Queries Qdrant  \r\n   - Calls LLM via ChatKit  \r\n   - Returns an answer  \r\n5. Frontend displays the answer in a chat bubble\r\n\r\n## FastAPI Endpoint Example\r\n\r\n```python\r\nfrom fastapi import FastAPI\r\nfrom pydantic import BaseModel\r\n\r\napp = FastAPI()\r\n\r\nclass QueryRequest(BaseModel):\r\n    question: str\r\n    selected_text: str | None = None\r\n\r\n@app.post("/query")\r\ndef query_rag(request: QueryRequest):\r\n    # If selected_text is provided, focus on that\r\n    # Otherwise, run normal RAG over the whole book\r\n    # Use Qdrant + ChatKit to build the answer\r\n    return {\r\n        "answer": "This will be generated from the book content.",\r\n        "sources": ["chapter-4-rag-basics.md", "chapter-5-qdrant-setup.md"]\r\n    }\n'})})]})}function l(t={}){const{wrapper:e}={...(0,o.R)(),...t.components};return e?(0,a.jsx)(e,{...t,children:(0,a.jsx)(d,{...t})}):d(t)}}}]);