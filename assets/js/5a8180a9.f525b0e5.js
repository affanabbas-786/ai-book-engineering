"use strict";(globalThis.webpackChunkmatrix_book=globalThis.webpackChunkmatrix_book||[]).push([[642],{8453:(e,t,n)=>{n.d(t,{R:()=>s,x:()=>i});var r=n(6540);const a={},o=r.createContext(a);function s(e){const t=r.useContext(o);return r.useMemo(function(){return"function"==typeof e?e(t):{...t,...e}},[t,e])}function i(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:s(e.components),r.createElement(o.Provider,{value:t},e.children)}},8783:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>c,contentTitle:()=>i,default:()=>l,frontMatter:()=>s,metadata:()=>r,toc:()=>h});const r=JSON.parse('{"id":"chapter-6-chatbot-integration","title":"chapter-6-chatbot-integration","description":"---","source":"@site/docs/chapter-6-chatbot-integration.md","sourceDirName":".","slug":"/chapter-6-chatbot-integration","permalink":"/ai-book-engineering/docs/chapter-6-chatbot-integration","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 5 \u2013 Qdrant Cloud + Embeddings + FastAPI","permalink":"/ai-book-engineering/docs/chapter-5-qdrant-setup"},"next":{"title":"chapter-7-subagents-skills","permalink":"/ai-book-engineering/docs/chapter-7-subagents-skills"}}');var a=n(4848),o=n(8453);const s={},i=void 0,c={},h=[{value:"6\ufe0f\u20e3 <code>chapter-6-chatbot-integration.md</code>",id:"6\ufe0f\u20e3-chapter-6-chatbot-integrationmd",level:2}];function d(e){const t={code:"code",h2:"h2",hr:"hr",pre:"pre",...(0,o.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(t.hr,{}),"\n",(0,a.jsxs)(t.h2,{id:"6\ufe0f\u20e3-chapter-6-chatbot-integrationmd",children:["6\ufe0f\u20e3 ",(0,a.jsx)(t.code,{children:"chapter-6-chatbot-integration.md"})]}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-markdown",children:'---\r\nid: chapter-6-chatbot-integration\r\ntitle: Chapter 6 \u2013 Integrating ChatKit Chatbot into the Book\r\n---\r\n\r\nNow we connect the **FastAPI RAG backend** to a **chat interface** that appears inside the Docusaurus site.\r\n\r\nWe use **OpenAI ChatKit / Agents SDK** to build a flexible chatbot client.\r\n\r\n## ChatKit Overview\r\n\r\nChatKit helps you:\r\n\r\n- Define conversation state and tools  \r\n- Call your own backend (FastAPI) as a tool  \r\n- Stream responses to the frontend  \r\n- Build customized chat experiences\r\n\r\n## High-Level Flow\r\n\r\n1. User opens the **Chat** page inside the Docusaurus book  \r\n2. User types a question (or selects some text and then asks a question)  \r\n3. Frontend sends the question to FastAPI `/query` endpoint  \r\n4. FastAPI:\r\n   - Queries Qdrant  \r\n   - Calls LLM via ChatKit  \r\n   - Returns an answer  \r\n5. Frontend displays the answer in a chat bubble\r\n\r\n## FastAPI Endpoint Example\r\n\r\n```python\r\nfrom fastapi import FastAPI\r\nfrom pydantic import BaseModel\r\n\r\napp = FastAPI()\r\n\r\nclass QueryRequest(BaseModel):\r\n    question: str\r\n    selected_text: str | None = None\r\n\r\n@app.post("/query")\r\ndef query_rag(request: QueryRequest):\r\n    # If selected_text is provided, focus on that\r\n    # Otherwise, run normal RAG over the whole book\r\n    # Use Qdrant + ChatKit to build the answer\r\n    return {\r\n        "answer": "This will be generated from the book content.",\r\n        "sources": ["chapter-4-rag-basics.md", "chapter-5-qdrant-setup.md"]\r\n    }\n'})})]})}function l(e={}){const{wrapper:t}={...(0,o.R)(),...e.components};return t?(0,a.jsx)(t,{...e,children:(0,a.jsx)(d,{...e})}):d(e)}}}]);